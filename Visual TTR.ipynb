{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognition with TTR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bridging between perceptual and conceptual domains\n",
    "\n",
    "Let's apply the object detection representation proposed in Dobnik & Cooper's *Interfacing language, spatial perception and cognition in TTR* to image recognition.\n",
    "\n",
    "![Fig 8](fig/lspc-fig8.png)\n",
    "\n",
    "Here, we use `Image` instead of `PointMap` for the whole, but instead of `reg:PointMap` we use yet another type (and rename it), `seg:Segment`. In Cooper's case the same type can be used to represent both the region and the whole, because a `PointMap` is a set of absolute positions. With `Image`, positions are relative to an origin, which needs to be specified when cropping.\n",
    "\n",
    "I guess in the general case, the domain of an `ObjectDetector` function need not be the same as the `reg` fields in the output elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7FF40400E588>'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('pyttr')\n",
    "from pyttr.ttrtypes import *\n",
    "from pyttr.utils import *\n",
    "import PIL.Image\n",
    "\n",
    "ttrace()\n",
    "\n",
    "# Basic types.\n",
    "\n",
    "Ind = BType('Ind')\n",
    "\n",
    "Int = BType('Int')\n",
    "Int.learn_witness_condition(lambda x: isinstance(x, int))\n",
    "print(Int.query(365))\n",
    "\n",
    "Image = BType('Image')\n",
    "Image.learn_witness_condition(lambda x: isinstance(x, PIL.Image.Image))\n",
    "img = PIL.Image.open('res/dogcar.jpg')\n",
    "print(Image.query(img))\n",
    "\n",
    "# Segment type: a rectangular area of a given image.\n",
    "\n",
    "Segment = RecType({#'i': Image,\n",
    "    'cx': Int, 'cy': Int, 'w': Int, 'h': Int})\n",
    "print(Segment.query(Rec({#'i': img,\n",
    "    'cx': 100, 'cy': 150, 'w': 40, 'h': 20})))\n",
    "\n",
    "# Redefine Image.show() to work with Rec.show().\n",
    "def image_show(self):\n",
    "    return str(self)\n",
    "PIL.Image.Image.show = image_show\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ppty = FunType(Ind, Ty)\n",
    "ImageDetection = RecType({'seg': Segment, 'pfun': Ppty})\n",
    "ImageDetections = ListType(ImageDetection)\n",
    "ObjectDetector = FunType(Image, ImageDetections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection model YOLO\n",
    "\n",
    "Requires OpenCV and [Darkflow](https://github.com/thtrieu/darkflow). `yolo.weights` is from [Yolo](https://pjreddie.com/darknet/yolo/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing yolo/yolo.cfg\n",
      "Loading yolo/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.03660297393798828s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "Finished in 7.426919460296631s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import numpy as np\n",
    "\n",
    "tfnet = TFNet({\"model\": \"yolo/yolo.cfg\", \"load\": \"yolo/yolo.weights\",\n",
    "    'config': 'yolo', \"threshold\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Make preds and ptypes identifiable by their predicate names.\n",
    "# From now on, use mktype().\n",
    "ptypes = dict()\n",
    "def mkptype(sym, types=[Ind], vars=['v']):\n",
    "    id = '/'.join([sym, ','.join(show(type) for type in types), ','.join(vars)])\n",
    "    if id not in ptypes:\n",
    "        ptypes[id] = PType(Pred(sym, types), vars)\n",
    "    return ptypes[id]\n",
    "\n",
    "print(show(mkptype('rabbit') is mkptype('rabbit')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy1xy2_to_cwh(x1, y1, x2, y2):\n",
    "    '''Transform to center, width and height.'''\n",
    "    return {'cx': int(x1/2 + x2/2), 'cy': int(y1/2 + y2/2), 'w': x2 - x1, 'h': y2 - y1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{pfun = lambda v:Ind . person(v), seg = {w = 276, cx = 138, cy = 654, h = 809}}\n",
      "{pfun = lambda v:Ind . person(v), seg = {w = 706, cx = 714, cy = 657, h = 796}}\n",
      "{pfun = lambda v:Ind . person(v), seg = {w = 380, cx = 194, cy = 888, h = 381}}\n",
      "{pfun = lambda v:Ind . car(v), seg = {w = 774, cx = 490, cy = 589, h = 979}}\n",
      "{pfun = lambda v:Ind . dog(v), seg = {w = 687, cx = 704, cy = 714, h = 718}}\n",
      "{pfun = lambda v:Ind . chair(v), seg = {w = 219, cx = 757, cy = 541, h = 210}}\n",
      "{pfun = lambda v:Ind . chair(v), seg = {w = 778, cx = 547, cy = 687, h = 783}}\n",
      "{pfun = lambda v:Ind . sofa(v), seg = {w = 957, cx = 486, cy = 677, h = 803}}\n",
      "{pfun = lambda v:Ind . cell phone(v), seg = {w = 187, cx = 93, cy = 588, h = 423}}\n",
      "{pfun = lambda v:Ind . clock(v), seg = {w = 71, cx = 44, cy = 544, h = 107}}\n"
     ]
    }
   ],
   "source": [
    "def yolo_detector(i):\n",
    "    return [Rec({\n",
    "        'seg': Rec({\n",
    "            #'i': i,\n",
    "            **xy1xy2_to_cwh(o['topleft']['x'], o['topleft']['y'], o['bottomright']['x'], o['bottomright']['y']),\n",
    "        }),\n",
    "        'pfun': Fun('v', Ind, mkptype(o['label'], 'v')),\n",
    "    }) for o in tfnet.return_predict(np.array(i))] # @todo RBG/BGR?\n",
    "\n",
    "image_detections = yolo_detector(img)\n",
    "\n",
    "print(ImageDetections.query(image_detections))\n",
    "print(ImageDetection.query(image_detections[0]))\n",
    "print(Ppty.query(image_detections[0].pfun))\n",
    "print(Segment.query(image_detections[0].seg))\n",
    "\n",
    "for image_detection in image_detections:\n",
    "    print(show(image_detection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a version where individuals are created too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{seg = {w = 276, cx = 138, cy = 654, h = 809}, pfun = lambda v:Ind . person(v), ind = a_{0}}\n",
      "['a_{0}', 'a_{1}', 'a_{2}', 'a_{3}', 'a_{4}', 'a_{5}', 'a_{6}', 'a_{7}', 'a_{8}', 'a_{9}']\n"
     ]
    }
   ],
   "source": [
    "DetectedInd = RecType({'seg': Segment, 'pfun': Ppty, 'ind': Ind})\n",
    "DetectedInds = ListType(DetectedInd)\n",
    "\n",
    "def yolo_detector_ind(i):\n",
    "    return [Rec({\n",
    "        'seg': Rec({\n",
    "            #'i': i,\n",
    "            **xy1xy2_to_cwh(o['topleft']['x'], o['topleft']['y'], o['bottomright']['x'], o['bottomright']['y']),\n",
    "        }),\n",
    "        'pfun': Fun('v', Ind, mkptype(o['label'], 'v')),\n",
    "        'ind': Ind.create(),\n",
    "    }) for o in tfnet.return_predict(np.array(i))]\n",
    "\n",
    "ind_detections = yolo_detector_ind(img)\n",
    "print(DetectedInds.query(ind_detections))\n",
    "print(show(ind_detections[0]))\n",
    "print(list(r.ind for r in ind_detections))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyttr.ttrtypes.PType object at 0x7ff39a12fba8>\n",
      "left(a, b)\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyttr.ttrtypes.PType at 0x7ff39a12fba8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An index of IndDetection by Ind.\n",
    "ind_dets = dict((r.ind, r) for r in ind_detections)\n",
    "\n",
    "Left = mkptype('left', [Ind, Ind], ['a', 'b'])\n",
    "Left.learn_witness_condition(lambda ab: ind_dets[ab[0]].seg.cx < ind_dets[ab[1]].seg.cx)\n",
    "print(show(Left))\n",
    "\n",
    "print(Left.query((ind_detections[0].ind, ind_detections[1].ind)))\n",
    "print(Left.query((ind_detections[1].ind, ind_detections[2].ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ClassifiedInd = RecType({'ind': Ind, 'pfun': Ppty})\n",
    "ClassifiedInds = ListType(ClassifiedInd)\n",
    "LocatedInd = RecType({'ind': Ind, 'seg': Segment})\n",
    "LocatedInds = ListType(LocatedInd)\n",
    "print(ClassifiedInds.query(ind_detections))\n",
    "print(LocatedInds.query(ind_detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by RobotState in Dobnik, Cooper & Larsson (2013).\n",
    "State = RecType({\n",
    "    'image': Image,\n",
    "    'objects': LocatedInds, # ???\n",
    "    'beliefs': RecTy,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe(image):\n",
    "    '''Perform classification and return a State.'''\n",
    "    dets = yolo_detector_ind(image)\n",
    "    beliefs = RecType({})\n",
    "    objects = []\n",
    "    for det in dets:\n",
    "        objects.append(Rec({'ind': det.ind, 'seg': det.seg}))\n",
    "        beliefs.addfield(gensym('c'), (det.pfun, [det.ind])) # We'd like to use ⇑objects[i] but ⇑ is not implemented?\n",
    "    return Rec({\n",
    "        'image': image,\n",
    "        'objects': objects,\n",
    "        'beliefs': beliefs,\n",
    "    })\n",
    "\n",
    "state = observe(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left\\{\\begin{array}{rcl}\n",
       "objects &=& \\left[\\begin{array}{rcl} \\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 276\\\\\n",
       "cx &=& 138\\\\\n",
       "cy &=& 654\\\\\n",
       "h &=& 809\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{10}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 706\\\\\n",
       "cx &=& 714\\\\\n",
       "cy &=& 657\\\\\n",
       "h &=& 796\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{11}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 380\\\\\n",
       "cx &=& 194\\\\\n",
       "cy &=& 888\\\\\n",
       "h &=& 381\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{12}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 774\\\\\n",
       "cx &=& 490\\\\\n",
       "cy &=& 589\\\\\n",
       "h &=& 979\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{13}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 687\\\\\n",
       "cx &=& 704\\\\\n",
       "cy &=& 714\\\\\n",
       "h &=& 718\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{14}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 219\\\\\n",
       "cx &=& 757\\\\\n",
       "cy &=& 541\\\\\n",
       "h &=& 210\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{15}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 778\\\\\n",
       "cx &=& 547\\\\\n",
       "cy &=& 687\\\\\n",
       "h &=& 783\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{16}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 957\\\\\n",
       "cx &=& 486\\\\\n",
       "cy &=& 677\\\\\n",
       "h &=& 803\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{17}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 187\\\\\n",
       "cx &=& 93\\\\\n",
       "cy &=& 588\\\\\n",
       "h &=& 423\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{18}\n",
       "\\end{array}\\right\\}\\\\\n",
       "\\left\\{\\begin{array}{rcl}\n",
       "seg &=& \\left\\{\\begin{array}{rcl}\n",
       "w &=& 71\\\\\n",
       "cx &=& 44\\\\\n",
       "cy &=& 544\\\\\n",
       "h &=& 107\n",
       "\\end{array}\\right\\}\\\\\n",
       "ind &=& a_{19}\n",
       "\\end{array}\\right\\}\\end{array}\\right]\\\\\n",
       "image &=& <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7FF40400E588>\\\\\n",
       "beliefs &=& \\left\\{\\begin{array}{rcl}\n",
       "c_{1} &:& \\langle \\lambda v:Ind . person(v), [a_{11}]\\rangle\\\\\n",
       "c_{5} &:& \\langle \\lambda v:Ind . chair(v), [a_{15}]\\rangle\\\\\n",
       "c_{6} &:& \\langle \\lambda v:Ind . chair(v), [a_{16}]\\rangle\\\\\n",
       "c_{4} &:& \\langle \\lambda v:Ind . dog(v), [a_{14}]\\rangle\\\\\n",
       "c_{0} &:& \\langle \\lambda v:Ind . person(v), [a_{10}]\\rangle\\\\\n",
       "c_{8} &:& \\langle \\lambda v:Ind . cell phone(v), [a_{18}]\\rangle\\\\\n",
       "c_{3} &:& \\langle \\lambda v:Ind . car(v), [a_{13}]\\rangle\\\\\n",
       "c_{9} &:& \\langle \\lambda v:Ind . clock(v), [a_{19}]\\rangle\\\\\n",
       "c_{7} &:& \\langle \\lambda v:Ind . sofa(v), [a_{17}]\\rangle\\\\\n",
       "c_{2} &:& \\langle \\lambda v:Ind . person(v), [a_{12}]\\rangle\n",
       "\\end{array}\\right\\}\n",
       "\\end{array}\\right\\}\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Latex\n",
    "Latex(to_ipython_latex(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Starting to sketch on whatever the output from parsing would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dog is to the left of a car\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left\\{\\begin{array}{rcl}\n",
       "a_1 &:& Ind\\\\\n",
       "c_{car} &:& \\langle \\lambda v:Ind . car(v), [a_2]\\rangle\\\\\n",
       "c_{left} &:& \\langle \\lambda a:Ind . \\lambda b:Ind . left(a, b), [a_1, a_2]\\rangle\\\\\n",
       "a_2 &:& Ind\\\\\n",
       "c_{dog} &:& \\langle \\lambda v:Ind . dog(v), [a_1]\\rangle\n",
       "\\end{array}\\right\\}\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"A dog is to the left of a car\")\n",
    "\n",
    "def create_abc(prop_a, prop_b, rel):\n",
    "    '''Creates a record type describing two individuals and a relation between them.'''\n",
    "    return RecType({\n",
    "        'a_1': Ind,\n",
    "        'a_2': Ind,\n",
    "        'c_{' + prop_a + '}': (Fun('v', Ind, mkptype(prop_a)), ['a_1']),\n",
    "        'c_{' + prop_b + '}': (Fun('v', Ind, mkptype(prop_b)), ['a_2']),\n",
    "        'c_{' + rel + '}': (Fun('a', Ind, Fun('b', Ind, mkptype(rel, [Ind, Ind], ['a', 'b']))), ['a_1', 'a_2'])\n",
    "    })\n",
    "\n",
    "question = create_abc('dog', 'car', 'left')\n",
    "\n",
    "Latex(to_ipython_latex(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple and naive parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left\\{\\begin{array}{rcl}\n",
       "a_1 &:& Ind\\\\\n",
       "c_{car} &:& \\langle \\lambda v:Ind . car(v), [a_2]\\rangle\\\\\n",
       "c_{left} &:& \\langle \\lambda a:Ind . \\lambda b:Ind . left(a, b), [a_1, a_2]\\rangle\\\\\n",
       "a_2 &:& Ind\\\\\n",
       "c_{dog} &:& \\langle \\lambda v:Ind . dog(v), [a_1]\\rangle\n",
       "\\end{array}\\right\\}\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> Det N 'is' P Det N\n",
    "Det -> 'a' | 'an'\n",
    "N -> 'dog' | 'car' | 'sofa' | 'person' | 'chair'\n",
    "P -> 'to' 'the' 'left' 'of' | 'to' 'the' 'right' 'of'\n",
    "\"\"\")\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "def parse(sent):\n",
    "    sent = sent.lower().split(' ')\n",
    "    for tree in parser.parse(sent):\n",
    "        return create_abc(tree[1][0], tree[5][0], tree[3][2])\n",
    "r = parse('A dog is to the left of a car')\n",
    "Latex(to_ipython_latex(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

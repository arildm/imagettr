{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognition with TTR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bridging between perceptual and conceptual domains\n",
    "\n",
    "Let's apply the object detection representation proposed in Dobnik & Cooper's *Interfacing language, spatial perception and cognition in TTR* to image recognition.\n",
    "\n",
    "![Fig 8](fig/lspc-fig8.png)\n",
    "\n",
    "Here, we use `Image` instead of `PointMap` for the whole, but instead of `reg:PointMap` we use yet another type (and rename it), `seg:Segment`. In Cooper's case the same type can be used to represent both the region and the whole, because a `PointMap` is a set of absolute positions. With `Image`, positions are relative to an origin, which needs to be specified when cropping.\n",
    "\n",
    "I guess in the general case, the domain of an `ObjectDetector` function need not be the same as the `reg` fields in the output elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7F72CF2F9438>'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('pyttr')\n",
    "from pyttr.ttrtypes import *\n",
    "from pyttr.utils import *\n",
    "import PIL.Image\n",
    "\n",
    "ttrace()\n",
    "\n",
    "# Basic types.\n",
    "\n",
    "Ind = BType('Ind')\n",
    "\n",
    "Int = BType('Int')\n",
    "Int.learn_witness_condition(lambda x: isinstance(x, int))\n",
    "print(Int.query(365))\n",
    "\n",
    "Image = BType('Image')\n",
    "Image.learn_witness_condition(lambda x: isinstance(x, PIL.Image.Image))\n",
    "img = PIL.Image.open('res/dogcar.jpg')\n",
    "print(Image.query(img))\n",
    "\n",
    "# Segment type: a rectangular area of a given image.\n",
    "\n",
    "Segment = RecType({#'i': Image,\n",
    "    'cx': Int, 'cy': Int, 'w': Int, 'h': Int})\n",
    "print(Segment.query(Rec({#'i': img,\n",
    "    'cx': 100, 'cy': 150, 'w': 40, 'h': 20})))\n",
    "\n",
    "# Redefine Image.show() to work with Rec.show().\n",
    "def image_show(self):\n",
    "    return str(self)\n",
    "PIL.Image.Image.show = image_show\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex(*objs):\n",
    "    texcode = '\\n\\n'.join(to_ipython_latex(obj) for obj in objs)\n",
    "    #print(texcode)\n",
    "    return Latex(texcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Ind$ and $Image$ are basic types.\n",
    "\n",
    "$Segment = \\left[\\begin{array}{rcl}\n",
    "\\text{cx} &:& Int\\\\\n",
    "\\text{cy} &:& Int\\\\\n",
    "\\text{w} &:& Int\\\\\n",
    "\\text{h} &:& Int\\\\\n",
    "\\end{array}\\right]$\n",
    "\n",
    "$Ppty = (Ind \\rightarrow Type)$\n",
    "\n",
    "$Object = \\left[ \\begin{array}{rcl}\n",
    "    \\text{pfun} &:& Ppty \\\\\n",
    "    \\text{seg} &:& Segment \\\\\n",
    "\\end{array} \\right]$\n",
    "\n",
    "$ObjectDetector = ( Image \\rightarrow [Object] )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{h} &:& Int\\\\\n",
       "\\text{w} &:& Int\\\\\n",
       "\\text{cx} &:& Int\\\\\n",
       "\\text{cy} &:& Int\n",
       "\\end{array}\\right]\\end{equation}\n",
       "\n",
       "\\begin{equation}\\left(\\begin{array}{rcl}\n",
       "Ind\\rightarrow Ty\n",
       "\\end{array}\\right)\\end{equation}\n",
       "\n",
       "\\begin{equation}\\left(\\begin{array}{rcl}\n",
       "Image\\rightarrow \\left[\\begin{array}{rcl}\n",
       "\\left[\\begin{array}{rcl}\n",
       "\\text{seg} &:& \\left[\\begin{array}{rcl}\n",
       "\\text{h} &:& Int\\\\\n",
       "\\text{w} &:& Int\\\\\n",
       "\\text{cx} &:& Int\\\\\n",
       "\\text{cy} &:& Int\n",
       "\\end{array}\\right]\\\\\n",
       "\\text{pfun} &:& \\left(\\begin{array}{rcl}\n",
       "Ind\\rightarrow Ty\n",
       "\\end{array}\\right)\n",
       "\\end{array}\\right]\n",
       "\\end{array}\\right]\n",
       "\\end{array}\\right)\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ppty = FunType(Ind, Ty)\n",
    "Object = RecType({'seg': Segment, 'pfun': Ppty})\n",
    "Objects = ListType(Object)\n",
    "ObjectDetector = FunType(Image, Objects)\n",
    "\n",
    "latex(Segment, Ppty, ObjectDetector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTTR utilities\n",
    "\n",
    "from functools import reduce\n",
    "    \n",
    "def copy_rectype(T):\n",
    "    R = RecType()\n",
    "    for k, v in T.comps.__dict__.items():\n",
    "        R.addfield(k, v)\n",
    "    return R\n",
    "\n",
    "def rectype_relabels(T, rlbs):\n",
    "    for k1, k2 in rlbs.items():\n",
    "        T.Relabel(k1, k2)\n",
    "    return T\n",
    "\n",
    "def rectype_merges(Ts):\n",
    "    return reduce((lambda T, U: T.merge(U)), Ts, RecType())\n",
    "\n",
    "def is_basic_type(T):\n",
    "    tn = lambda T: type(T).__name__\n",
    "    return (tn(T) == 'BType') if tn(T) != 'SingletonType' else is_basic_type(T.comps.base_type)\n",
    "\n",
    "def basic_fields(T):\n",
    "    return [k for k, v in T.comps.__dict__.items() if is_basic_type(v)]\n",
    "\n",
    "def nonbasic_fields(T):\n",
    "    return [k for k, v in T.comps.__dict__.items() if not is_basic_type(v)]\n",
    "\n",
    "ptypes = dict()\n",
    "def mkptype(sym, types=[Ind], vars=['v']):\n",
    "    \"\"\"Make preds and ptypes identifiable by their predicate names.\"\"\"\n",
    "    id = '/'.join([sym, ','.join(show(type) for type in types), ','.join(vars)])\n",
    "    if id not in ptypes:\n",
    "        ptypes[id] = PType(Pred(sym, types), vars)\n",
    "    return ptypes[id]\n",
    "\n",
    "def create_fun(pred_name, vars=['a']):\n",
    "    fun = mkptype(pred_name, vars=vars)\n",
    "    for v in reversed(vars):\n",
    "        fun = Fun(v, Ind, fun)\n",
    "    return fun\n",
    "\n",
    "# print(show(create_fun('bamba', 'abcd')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection model YOLO\n",
    "\n",
    "We use an object detection model to detect and recognize objects in an image. The output is modeled as a set of TTR records.\n",
    "\n",
    "Requires OpenCV and [Darkflow](https://github.com/thtrieu/darkflow). `yolo.weights` is from [Yolo](https://pjreddie.com/darknet/yolo/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing yolo/yolo.cfg\n",
      "Loading yolo/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.031154632568359375s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "Finished in 5.322499990463257s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import numpy as np\n",
    "\n",
    "tfnet = TFNet({\"model\": \"yolo/yolo.cfg\", \"load\": \"yolo/yolo.weights\",\n",
    "    'config': 'yolo', \"threshold\": 0.1})\n",
    "yolo_out = dict()\n",
    "def yolo(img):\n",
    "    if str(img) not in yolo_out:\n",
    "        yolo_out[str(img)] = tfnet.return_predict(np.array(img))\n",
    "    return yolo_out[str(img)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy1xy2_to_cwh(x1, y1, x2, y2):\n",
    "    '''Transform to center, width and height.'''\n",
    "    return {'cx': int(x1/2 + x2/2), 'cy': int(y1/2 + y2/2), 'w': x2 - x1, 'h': y2 - y1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{seg} &=& \\left[\\begin{array}{rcl}\n",
       "\\text{h} &=& 107\\\\\n",
       "\\text{w} &=& 71\\\\\n",
       "\\text{cx} &=& 44\\\\\n",
       "\\text{cy} &=& 544\n",
       "\\end{array}\\right]\\\\\n",
       "\\text{pfun} &=& \\lambda a:Ind\\ .\\ \\text{clock}(a)\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yolo_detector(i):\n",
    "    return [Rec({\n",
    "        'seg': Rec({\n",
    "            #'i': i,\n",
    "            **xy1xy2_to_cwh(o['topleft']['x'], o['topleft']['y'], o['bottomright']['x'], o['bottomright']['y']),\n",
    "        }),\n",
    "        'pfun': create_fun(o['label'].replace(' ', '_')),\n",
    "        \n",
    "    }) for o in yolo(i)] # @todo RBG/BGR?\n",
    "\n",
    "objs = yolo_detector(img)\n",
    "\n",
    "print(Objects.query(objs))\n",
    "print(Object.query(objs[0]))\n",
    "print(Ppty.query(objs[0].pfun))\n",
    "print(Segment.query(objs[0].seg))\n",
    "\n",
    "latex(objs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individualization function\n",
    "\n",
    "The object detection model gave us evidence that certain segments contain something that present certain properties/classes.\n",
    "\n",
    "Now let's recognize that there are individuals which are located at those segments and having those properties.\n",
    "\n",
    "**Is the domain of $Individualize$ really objects *of type* $IndObj$? Can a record type be *of* another record type?**\n",
    "\n",
    "$IndObj = \\left[\\begin{array}{rcl}\n",
    "\\text{x} &:& Ind\\\\\n",
    "\\text{cp} &:& Type\\\\\n",
    "\\text{loc} &:& Type\\\\\n",
    "\\text{cl} &:& Type\\\\\n",
    "\\end{array}\\right]$?\n",
    "\n",
    "$Individualize : (Object \\rightarrow IndObj)$ or $(Object \\rightarrow Type)$ or $(Object \\rightarrow RecType)$?\n",
    "\n",
    "$Individualize = \\lambda r : Object\\ . \\left[\\begin{array}{rcl}\n",
    "    \\text{x} &:& Ind \\\\\n",
    "    \\text{cp} &:& r.\\text{pfun}(\\text{x}) \\\\\n",
    "    \\text{loc} &:& Segment_{r.\\text{seg}}\\\\\n",
    "    \\text{cl} &:& \\text{location}(\\text{x}, \\text{loc}) \\\\\n",
    "\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{x}_\\text{14} &:& Ind\\\\\n",
       "\\text{cl}_\\text{9} &:& \\text{location}(x_{14}, loc_{14})\\\\\n",
       "\\text{cp}_\\text{9} &:& \\text{clock}(x_{14})\\\\\n",
       "\\text{loc}_\\text{14} &:& \\left[\\begin{array}{rcl}\n",
       "\\text{h} &:& Int\\\\\n",
       "\\text{w} &:& Int\\\\\n",
       "\\text{cx} &:& Int\\\\\n",
       "\\text{cy} &:& Int\n",
       "\\end{array}\\right]_{\\left[\\begin{array}{rcl}\n",
       "\\text{h} &=& 107\\\\\n",
       "\\text{w} &=& 71\\\\\n",
       "\\text{cx} &=& 44\\\\\n",
       "\\text{cy} &=& 544\n",
       "\\end{array}\\right]}\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LocFun = create_fun('location', 'ab')\n",
    "\n",
    "def individualize(r):\n",
    "    x = gensym('x')\n",
    "    loc = gensym('loc')\n",
    "    return RecType({\n",
    "        x: Ind,\n",
    "        gensym('cp'): r.pfun.app(x),\n",
    "        loc: SingletonType(Segment, r.seg),\n",
    "        gensym('cl'): LocFun.app(x).app(LazyObj([loc])),\n",
    "    })\n",
    "latex(individualize(objs[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining commitments\n",
    "\n",
    "All observed situations are combined into one, so they can be considered simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "objs_few = objs[2:5]\n",
    "situations = [individualize(r) for r in objs_few]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{loc}_\\text{11} &:& \\left[\\begin{array}{rcl}\n",
       "\\text{h} &:& Int\\\\\n",
       "\\text{w} &:& Int\\\\\n",
       "\\text{cx} &:& Int\\\\\n",
       "\\text{cy} &:& Int\n",
       "\\end{array}\\right]_{\\left[\\begin{array}{rcl}\n",
       "\\text{h} &=& 381\\\\\n",
       "\\text{w} &=& 380\\\\\n",
       "\\text{cx} &=& 194\\\\\n",
       "\\text{cy} &=& 888\n",
       "\\end{array}\\right]}\\\\\n",
       "\\text{x}_\\text{11} &:& Ind\\\\\n",
       "\\text{x}_\\text{13} &:& Ind\\\\\n",
       "\\text{cl}_\\text{8} &:& \\text{location}(x_{13}, loc_{13})\\\\\n",
       "\\text{cp}_\\text{6} &:& \\text{person}(x_{11})\\\\\n",
       "\\text{cp}_\\text{8} &:& \\text{dog}(x_{13})\\\\\n",
       "\\text{loc}_\\text{12} &:& \\left[\\begin{array}{rcl}\n",
       "\\text{h} &:& Int\\\\\n",
       "\\text{w} &:& Int\\\\\n",
       "\\text{cx} &:& Int\\\\\n",
       "\\text{cy} &:& Int\n",
       "\\end{array}\\right]_{\\left[\\begin{array}{rcl}\n",
       "\\text{h} &=& 979\\\\\n",
       "\\text{w} &=& 774\\\\\n",
       "\\text{cx} &=& 490\\\\\n",
       "\\text{cy} &=& 589\n",
       "\\end{array}\\right]}\\\\\n",
       "\\text{x}_\\text{12} &:& Ind\\\\\n",
       "\\text{loc}_\\text{13} &:& \\left[\\begin{array}{rcl}\n",
       "\\text{h} &:& Int\\\\\n",
       "\\text{w} &:& Int\\\\\n",
       "\\text{cx} &:& Int\\\\\n",
       "\\text{cy} &:& Int\n",
       "\\end{array}\\right]_{\\left[\\begin{array}{rcl}\n",
       "\\text{h} &=& 718\\\\\n",
       "\\text{w} &=& 687\\\\\n",
       "\\text{cx} &=& 704\\\\\n",
       "\\text{cy} &=& 714\n",
       "\\end{array}\\right]}\\\\\n",
       "\\text{cl}_\\text{6} &:& \\text{location}(x_{11}, loc_{11})\\\\\n",
       "\\text{cp}_\\text{7} &:& \\text{car}(x_{12})\\\\\n",
       "\\text{cl}_\\text{7} &:& \\text{location}(x_{12}, loc_{12})\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "sitmerge = rectype_merges(situations)\n",
    "latex(sitmerge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'cy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-62f93f2f1908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_relations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitmerge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation_relation_classifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0msitmergerels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrectype_merges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msitmerge\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRecType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mgensym\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlatex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitmergerels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-62f93f2f1908>\u001b[0m in \u001b[0;36mdetect_relations\u001b[0;34m(T, classifiers)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mrels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-62f93f2f1908>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'left'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m'right'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m'above'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m'below'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'cy'"
     ]
    }
   ],
   "source": [
    "location_relation_classifiers = {\n",
    "    'left': lambda a, b: a.cx < b.cx,\n",
    "    'right': lambda a, b: a.cx > b.cx,\n",
    "    'above': lambda a, b: a.cy < b.cy,\n",
    "    'below': lambda a, b: a.cy > b.cy,\n",
    "}\n",
    "\n",
    "def get_locs(T):\n",
    "    locs = dict()\n",
    "    for c in nonbasic_fields(T):\n",
    "        t = T.comps.__dict__[c]\n",
    "        if isinstance(t, PType) and t.comps.pred.name == 'location':\n",
    "            locs[t.comps.args[0]] = t.comps.args[1]\n",
    "    return locs\n",
    "\n",
    "def detect_relations(T, classifiers):\n",
    "    locs = get_locs(T)\n",
    "    rels = []\n",
    "    for k, f in classifiers:\n",
    "        for x1, x2 in product(locs, locs):\n",
    "            if f(locs[x1], locs[x2]):\n",
    "                rels.append(create_fun(k, 'ab').app(x1).app(x2))\n",
    "    return rels\n",
    "    \n",
    "rels = detect_relations(sitmerge, location_relation_classifiers.items())\n",
    "sitmergerels = rectype_merges([sitmerge] + [RecType({gensym('rel'): rel}) for rel in rels])\n",
    "latex(sitmergerels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A car is to the left of a dog\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{c}_\\text{34} &:& \\text{car}(x)\\\\\n",
       "\\text{c}_\\text{36} &:& \\text{dog}(y)\\\\\n",
       "\\text{y} &:& Ind\\\\\n",
       "\\text{c}_\\text{35} &:& \\text{left}(x, y)\\\\\n",
       "\\text{x} &:& Ind\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Parsing to PyTTR cannot really be done directly. NLTK feature grammars support strings and FOPC. Variable substitution\n",
    "# is only allowed in FOPC, so we produce a mix of both.\n",
    "# - String: comma-separated list of record type fields.\n",
    "# - FOPC expression: conjunction of ptypes, for each of which we create a new field.\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(r'''\n",
    "%start S\n",
    "S[SEM=<?s(x) & ?vp(x, y)>] -> NP[SEM=?s] VP[SEM=?vp]\n",
    "NP[SEM=<?det(?n)>] -> Det[SEM=?det] N[SEM=?n]\n",
    "Det[SEM=<\\P a.P(a)>] -> 'a' | 'an'\n",
    "N[SEM=<dog>] -> 'dog'\n",
    "N[SEM=<car>] -> 'car'\n",
    "N[SEM=<person>] -> 'person'\n",
    "N[SEM=<chair>] -> 'chair'\n",
    "VP[SEM=?pp] -> 'is' PP[SEM=?pp]\n",
    "PP[SEM=<\\a b.(?prep(a, b) & ?o(b))>] -> Prep[SEM=?prep] NP[SEM=?o]\n",
    "Prep[SEM=<left>] -> 'to' 'the' 'left' 'of'\n",
    "Prep[SEM=<right>] -> 'to' 'the' 'right' 'of'\n",
    "Prep[SEM=<above>] -> 'above'\n",
    "Prep[SEM=<under>] -> 'under'\n",
    "''')\n",
    "parser = nltk.FeatureChartParser(grammar)\n",
    "\n",
    "texts = [\n",
    "    'A dog is to the left of a car',\n",
    "    'A car is to the left of a dog',\n",
    "#     'There is a dog to the left of a car',\n",
    "#     'Is the dog to the left of the car',\n",
    "#     'Is there a dog to the left of the car',\n",
    "]\n",
    "\n",
    "def fopc_to_pyttr(expr, T=RecType()):\n",
    "    \"\"\"Turns a FOPC object into a RecType.\"\"\"\n",
    "    from nltk.sem.logic import ApplicationExpression, AndExpression\n",
    "    if isinstance(expr, ApplicationExpression):\n",
    "        pred, args = expr.uncurry()\n",
    "        T.addfield(gensym('c'), mkptype(str(pred), vars=[str(a) for a in args]))\n",
    "        for x in args:\n",
    "            if str(x) not in T.comps.__dict__:\n",
    "                T.addfield(str(x), Ind)\n",
    "    if isinstance(expr, AndExpression):\n",
    "        fopc_to_pyttr(expr.first, T)\n",
    "        fopc_to_pyttr(expr.second, T)\n",
    "    return T\n",
    "\n",
    "def eng_to_pyttr(text):\n",
    "    trees = parser.parse(text.lower().split())\n",
    "    sem = nltk.sem.root_semrep(list(trees)[0])\n",
    "    T = fopc_to_pyttr(sem)\n",
    "    return T\n",
    "\n",
    "print(texts[1])\n",
    "latex(eng_to_pyttr(texts[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking text against image\n",
    "\n",
    "Essentially, we would like to check if the situation observed is a subtype of the situation described by the text/question, whether $Q \\sqsupseteq A$. A new problem here is that field labels do not match, even if the field values (the types) match. We thus need to consider all (?) relabelings of Q:\n",
    "\n",
    "A record type $T_1$ is a *relabel-subtype* of $T_2$ if there is a relabeling of $T_1$, $T_{1_{rlb}}$ where $T_{1_{rlb}} \\sqsubseteq T_2$.\n",
    "\n",
    "Could we forget field labels and just look at the two sets of field values? Not really, because we have dependent types, so $\\text{dog}(x_1) â‰  \\text{dog}(x_2)$. We need to carry out each candidate *relabeling* and check subtypeness. In practice, and in this case, relabeling the basic-type ($Ind$) fields is enough, because those are the only ones whose labels appear in dependent fields. For each basic-field relabeling, we can then kind of forget labels and just find subtypeness of field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_2': 'rel_{6}', 'y': 'x_{3}', 'c_3': 'prop_{3}', 'c_1': 'prop_{2}', 'x': 'x_{2}'}\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{x}_\\text{2} &:& Ind\\\\\n",
       "\\text{x}_\\text{3} &:& Ind\\\\\n",
       "\\text{prop}_\\text{3} &:& \\text{dog}(x_{3})\\\\\n",
       "\\text{rel}_\\text{6} &:& \\text{left}(x_{2}, x_{3})\\\\\n",
       "\\text{prop}_\\text{2} &:& \\text{car}(x_{2})\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations, combinations\n",
    "\n",
    "def find_subtype_relabeling(T, U):\n",
    "    '''Could record type T be a sub type of record type U if relabeling in T is allowed?'''\n",
    "    # Find possible relabelings for basic-type fields\n",
    "    basic_label_permutations = set(ps[:len(basic_fields(U))] for ps in permutations(basic_fields(T)))\n",
    "    \n",
    "    for tks in basic_label_permutations:\n",
    "        # Copy U and try a basic-fields relabeling\n",
    "        U2 = copy_rectype(U)\n",
    "        rlb = dict(zip(basic_fields(U), tks))\n",
    "        rectype_relabels(U2, rlb)\n",
    "        \n",
    "        # For each U field, find a T field that is a subtype\n",
    "        match = dict()\n",
    "        for uk in nonbasic_fields(U2):\n",
    "            for tk in nonbasic_fields(T):\n",
    "                if T.comps.__dict__[tk].subtype_of(U2.comps.__dict__[uk]):\n",
    "                    match[uk] = tk\n",
    "                    break\n",
    "            if uk not in match:\n",
    "                break\n",
    "\n",
    "        # Successful if all non-basic fields match.\n",
    "        if len(match) == len(nonbasic_fields(U2)):\n",
    "            return dict(**rlb, **match)\n",
    "    return None\n",
    "\n",
    "obs = sitmergerels\n",
    "r = eng_to_pyttr(texts[1])\n",
    "print(find_subtype_relabeling(obs, r))\n",
    "r2 = rectype_relabels(copy_rectype(r), find_subtype_relabeling(obs, r))\n",
    "print(obs.subtype_of(r2))\n",
    "latex(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

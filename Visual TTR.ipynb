{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognition with TTR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bridging between perceptual and conceptual domains\n",
    "\n",
    "Let's apply the object detection representation proposed in Dobnik & Cooper's *Interfacing language, spatial perception and cognition in TTR* to image recognition.\n",
    "\n",
    "![Fig 8](fig/lspc-fig8.png)\n",
    "\n",
    "Here, we use `Image` instead of `PointMap` for the whole, but instead of `reg:PointMap` we use yet another type (and rename it), `seg:Segment`. In Cooper's case the same type can be used to represent both the region and the whole, because a `PointMap` is a set of absolute positions. With `Image`, positions are relative to an origin, which needs to be specified when cropping.\n",
    "\n",
    "I guess in the general case, the domain of an `ObjectDetector` function need not be the same as the `reg` fields in the output elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1080x1080 at 0x7FD6480714A8>'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('pyttr')\n",
    "from pyttr.ttrtypes import *\n",
    "from pyttr.utils import *\n",
    "import PIL.Image\n",
    "\n",
    "ttrace()\n",
    "\n",
    "# Basic types.\n",
    "\n",
    "Ind = BType('Ind')\n",
    "\n",
    "Int = BType('Int')\n",
    "Int.learn_witness_condition(lambda x: isinstance(x, int))\n",
    "print(Int.query(365))\n",
    "\n",
    "Image = BType('Image')\n",
    "Image.learn_witness_condition(lambda x: isinstance(x, PIL.Image.Image))\n",
    "img = PIL.Image.open('res/dogcar.jpg')\n",
    "print(Image.query(img))\n",
    "\n",
    "# Segment type: a rectangular area of a given image.\n",
    "\n",
    "Segment = RecType({#'i': Image,\n",
    "    'cx': Int, 'cy': Int, 'w': Int, 'h': Int})\n",
    "print(Segment.query(Rec({#'i': img,\n",
    "    'cx': 100, 'cy': 150, 'w': 40, 'h': 20})))\n",
    "\n",
    "# Redefine Image.show() to work with Rec.show().\n",
    "def image_show(self):\n",
    "    return str(self)\n",
    "PIL.Image.Image.show = image_show\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex(*objs):\n",
    "    texcode = '\\n\\n'.join(to_ipython_latex(obj) for obj in objs)\n",
    "    #print(texcode)\n",
    "    return Latex(texcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Ind$ and $Image$ are basic types.\n",
    "\n",
    "$Segment = \\left[\\begin{array}{rcl}\n",
    "\\text{cx} &:& Int\\\\\n",
    "\\text{cy} &:& Int\\\\\n",
    "\\text{w} &:& Int\\\\\n",
    "\\text{h} &:& Int\\\\\n",
    "\\end{array}\\right]$\n",
    "\n",
    "$Ppty = (Ind \\rightarrow Type)$\n",
    "\n",
    "$Object = \\left[ \\begin{array}{rcl}\n",
    "    \\text{pfun} &:& Ppty \\\\\n",
    "    \\text{seg} &:& Segment \\\\\n",
    "\\end{array} \\right]$\n",
    "\n",
    "$ObjectDetector = ( Image \\rightarrow [Object] )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{cy} &:& Int\\\\\n",
       "\\text{cx} &:& Int\\\\\n",
       "\\text{h} &:& Int\\\\\n",
       "\\text{w} &:& Int\n",
       "\\end{array}\\right]\\end{equation}\n",
       "\n",
       "\\begin{equation}\\left(\\begin{array}{rcl}\n",
       "Ind\\rightarrow Ty\n",
       "\\end{array}\\right)\\end{equation}\n",
       "\n",
       "\\begin{equation}\\left(\\begin{array}{rcl}\n",
       "Image\\rightarrow \\left[\\begin{array}{rcl}\n",
       "\\left[\\begin{array}{rcl}\n",
       "\\text{pfun} &:& \\left(\\begin{array}{rcl}\n",
       "Ind\\rightarrow Ty\n",
       "\\end{array}\\right)\\\\\n",
       "\\text{seg} &:& \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &:& Int\\\\\n",
       "\\text{cx} &:& Int\\\\\n",
       "\\text{h} &:& Int\\\\\n",
       "\\text{w} &:& Int\n",
       "\\end{array}\\right]\n",
       "\\end{array}\\right]\n",
       "\\end{array}\\right]\n",
       "\\end{array}\\right)\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ppty = FunType(Ind, Ty)\n",
    "Object = RecType({'seg': Segment, 'pfun': Ppty})\n",
    "Objects = ListType(Object)\n",
    "ObjectDetector = FunType(Image, Objects)\n",
    "\n",
    "latex(Segment, Ppty, ObjectDetector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTTR utilities\n",
    "\n",
    "from functools import reduce\n",
    "    \n",
    "def copy_rectype(T):\n",
    "    R = RecType()\n",
    "    for k, v in T.comps.__dict__.items():\n",
    "        R.addfield(k, v)\n",
    "    return R\n",
    "\n",
    "def rectype_relabels(T, rlbs):\n",
    "    for k1, k2 in rlbs.items():\n",
    "        T.Relabel(k1, k2)\n",
    "    return T\n",
    "\n",
    "def rectype_merges(Ts):\n",
    "    return reduce((lambda T, U: T.merge(U)), Ts, RecType())\n",
    "\n",
    "def is_basic_type(T):\n",
    "    tn = lambda T: type(T).__name__\n",
    "    return (tn(T) == 'BType') if tn(T) != 'SingletonType' else is_basic_type(T.comps.base_type)\n",
    "\n",
    "def basic_fields(T):\n",
    "    return [k for k, v in T.comps.__dict__.items() if is_basic_type(v)]\n",
    "\n",
    "def nonbasic_fields(T):\n",
    "    return [k for k, v in T.comps.__dict__.items() if not is_basic_type(v)]\n",
    "\n",
    "ptypes = dict()\n",
    "def mkptype(sym, types=[Ind], vars=['v']):\n",
    "    \"\"\"Make preds and ptypes identifiable by their predicate names.\"\"\"\n",
    "    id = '/'.join([sym, ','.join(show(type) for type in types), ','.join(vars)])\n",
    "    if id not in ptypes:\n",
    "        ptypes[id] = PType(Pred(sym, types), vars)\n",
    "    return ptypes[id]\n",
    "\n",
    "def create_fun(pred_name, vars=['a']):\n",
    "    fun = mkptype(pred_name, vars=vars)\n",
    "    for v in reversed(vars):\n",
    "        fun = Fun(v, Ind, fun)\n",
    "    return fun\n",
    "\n",
    "# print(show(create_fun('bamba', 'abcd')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection model YOLO\n",
    "\n",
    "We use an object detection model to detect and recognize objects in an image. The output is modeled as a set of TTR records.\n",
    "\n",
    "Requires OpenCV and [Darkflow](https://github.com/thtrieu/darkflow). `yolo.weights` is from [Yolo](https://pjreddie.com/darknet/yolo/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing yolo/yolo.cfg\n",
      "Loading yolo/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.027223825454711914s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "Finished in 5.607311964035034s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import numpy as np\n",
    "\n",
    "tfnet = TFNet({\"model\": \"yolo/yolo.cfg\", \"load\": \"yolo/yolo.weights\",\n",
    "    'config': 'yolo', \"threshold\": 0.1})\n",
    "yolo_out = dict()\n",
    "def yolo(img):\n",
    "    if str(img) not in yolo_out:\n",
    "        yolo_out[str(img)] = tfnet.return_predict(np.array(img))\n",
    "    return yolo_out[str(img)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy1xy2_to_cwh(x1, y1, x2, y2):\n",
    "    '''Transform to center, width and height.'''\n",
    "    return {'cx': int(x1/2 + x2/2), 'cy': int(y1/2 + y2/2), 'w': x2 - x1, 'h': y2 - y1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{pfun} &=& \\lambda a:Ind\\ .\\ \\text{clock}(a)\\\\\n",
       "\\text{seg} &=& \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &=& 544\\\\\n",
       "\\text{cx} &=& 44\\\\\n",
       "\\text{h} &=& 107\\\\\n",
       "\\text{w} &=& 71\n",
       "\\end{array}\\right]\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yolo_detector(i):\n",
    "    return [Rec({\n",
    "        'seg': Rec({\n",
    "            #'i': i,\n",
    "            **xy1xy2_to_cwh(o['topleft']['x'], o['topleft']['y'], o['bottomright']['x'], o['bottomright']['y']),\n",
    "        }),\n",
    "        'pfun': create_fun(o['label'].replace(' ', '_')),\n",
    "        \n",
    "    }) for o in yolo(i)] # @todo RBG/BGR?\n",
    "\n",
    "objs = yolo_detector(img)\n",
    "\n",
    "print(Objects.query(objs))\n",
    "print(Object.query(objs[0]))\n",
    "print(Ppty.query(objs[0].pfun))\n",
    "print(Segment.query(objs[0].seg))\n",
    "\n",
    "latex(objs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individualization function\n",
    "\n",
    "The object detection model gave us evidence that certain segments contain something that present certain properties/classes.\n",
    "\n",
    "Now let's recognize that there are individuals which are located at those segments and having those properties.\n",
    "\n",
    "**Is the domain of $Individualize$ really objects *of type* $IndObj$? Can a record type be *of* another record type?**\n",
    "\n",
    "$IndObj = \\left[\\begin{array}{rcl}\n",
    "\\text{x} &:& Ind\\\\\n",
    "\\text{c}_{prop} &:& Type\\\\\n",
    "\\text{c}_{loc} &:& Type\\\\\n",
    "\\end{array}\\right]$?\n",
    "\n",
    "$Individualize : (Object \\rightarrow IndObj)$ or $Individualize : (Object \\rightarrow Type)$ ?\n",
    "\n",
    "$Individualize = \\lambda r : Object\\ . \\left[\\begin{array}{rcl}\n",
    "    \\text{x} &:& Ind \\\\\n",
    "    \\text{c}_{prop} &:& r.\\text{pfun}(\\text{x}) \\\\\n",
    "    \\text{c}_{loc} &:& \\text{location}(\\text{x}, r.\\text{seg}) \\\\\n",
    "\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{prop}_\\text{0} &:& \\text{clock}(x_{0})\\\\\n",
       "\\text{x}_\\text{0} &:& Ind\\\\\n",
       "\\text{loc}_\\text{0} &:& \\text{location}(x_{0}, \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &=& 544\\\\\n",
       "\\text{cx} &=& 44\\\\\n",
       "\\text{h} &=& 107\\\\\n",
       "\\text{w} &=& 71\n",
       "\\end{array}\\right])\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LocFun = create_fun('location', 'ab')\n",
    "\n",
    "def individualize(r):\n",
    "    x = gensym('x')\n",
    "    return RecType({\n",
    "        x: Ind,\n",
    "        gensym('prop'): r.pfun.app(x),\n",
    "        gensym('loc'): LocFun.app(x).app(r.seg),\n",
    "    })\n",
    "latex(individualize(objs[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining commitments\n",
    "\n",
    "All observed situations are combined into one, so they can be considered simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "objs_few = objs[2:5]\n",
    "situations = [individualize(r) for r in objs_few]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{prop}_\\text{2} &:& \\text{car}(x_{2})\\\\\n",
       "\\text{prop}_\\text{1} &:& \\text{person}(x_{1})\\\\\n",
       "\\text{x}_\\text{3} &:& Ind\\\\\n",
       "\\text{prop}_\\text{3} &:& \\text{dog}(x_{3})\\\\\n",
       "\\text{loc}_\\text{3} &:& \\text{location}(x_{3}, \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &=& 714\\\\\n",
       "\\text{cx} &=& 704\\\\\n",
       "\\text{h} &=& 718\\\\\n",
       "\\text{w} &=& 687\n",
       "\\end{array}\\right])\\\\\n",
       "\\text{loc}_\\text{2} &:& \\text{location}(x_{2}, \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &=& 589\\\\\n",
       "\\text{cx} &=& 490\\\\\n",
       "\\text{h} &=& 979\\\\\n",
       "\\text{w} &=& 774\n",
       "\\end{array}\\right])\\\\\n",
       "\\text{x}_\\text{2} &:& Ind\\\\\n",
       "\\text{x}_\\text{1} &:& Ind\\\\\n",
       "\\text{loc}_\\text{1} &:& \\text{location}(x_{1}, \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &=& 888\\\\\n",
       "\\text{cx} &=& 194\\\\\n",
       "\\text{h} &=& 381\\\\\n",
       "\\text{w} &=& 380\n",
       "\\end{array}\\right])\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "sitmerge = rectype_merges(situations)\n",
    "latex(sitmerge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{prop}_\\text{2} &:& \\text{car}(x_{2})\\\\\n",
       "\\text{rel}_\\text{4} &:& \\text{above}(x_{2}, x_{1})\\\\\n",
       "\\text{prop}_\\text{3} &:& \\text{dog}(x_{3})\\\\\n",
       "\\text{x}_\\text{3} &:& Ind\\\\\n",
       "\\text{rel}_\\text{10} &:& \\text{left}(x_{1}, x_{2})\\\\\n",
       "\\text{rel}_\\text{1} &:& \\text{right}(x_{3}, x_{2})\\\\\n",
       "\\text{rel}_\\text{11} &:& \\text{left}(x_{1}, x_{3})\\\\\n",
       "\\text{rel}_\\text{0} &:& \\text{right}(x_{2}, x_{1})\\\\\n",
       "\\text{prop}_\\text{1} &:& \\text{person}(x_{1})\\\\\n",
       "\\text{rel}_\\text{7} &:& \\text{below}(x_{1}, x_{2})\\\\\n",
       "\\text{x}_\\text{1} &:& Ind\\\\\n",
       "\\text{rel}_\\text{2} &:& \\text{right}(x_{3}, x_{1})\\\\\n",
       "\\text{rel}_\\text{6} &:& \\text{below}(x_{3}, x_{2})\\\\\n",
       "\\text{rel}_\\text{3} &:& \\text{above}(x_{2}, x_{3})\\\\\n",
       "\\text{rel}_\\text{5} &:& \\text{above}(x_{3}, x_{1})\\\\\n",
       "\\text{rel}_\\text{8} &:& \\text{below}(x_{1}, x_{3})\\\\\n",
       "\\text{loc}_\\text{1} &:& \\text{location}(x_{1}, \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &=& 888\\\\\n",
       "\\text{cx} &=& 194\\\\\n",
       "\\text{h} &=& 381\\\\\n",
       "\\text{w} &=& 380\n",
       "\\end{array}\\right])\\\\\n",
       "\\text{loc}_\\text{3} &:& \\text{location}(x_{3}, \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &=& 714\\\\\n",
       "\\text{cx} &=& 704\\\\\n",
       "\\text{h} &=& 718\\\\\n",
       "\\text{w} &=& 687\n",
       "\\end{array}\\right])\\\\\n",
       "\\text{loc}_\\text{2} &:& \\text{location}(x_{2}, \\left[\\begin{array}{rcl}\n",
       "\\text{cy} &=& 589\\\\\n",
       "\\text{cx} &=& 490\\\\\n",
       "\\text{h} &=& 979\\\\\n",
       "\\text{w} &=& 774\n",
       "\\end{array}\\right])\\\\\n",
       "\\text{x}_\\text{2} &:& Ind\\\\\n",
       "\\text{rel}_\\text{9} &:& \\text{left}(x_{2}, x_{3})\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_relation_classifiers = {\n",
    "    'left': lambda a, b: a.cx < b.cx,\n",
    "    'right': lambda a, b: a.cx > b.cx,\n",
    "    'above': lambda a, b: a.cy < b.cy,\n",
    "    'below': lambda a, b: a.cy > b.cy,\n",
    "}\n",
    "\n",
    "def get_locs(T):\n",
    "    locs = dict()\n",
    "    for c in nonbasic_fields(T):\n",
    "        t = T.comps.__dict__[c]\n",
    "        if isinstance(t, PType) and t.comps.pred.name == 'location':\n",
    "            locs[t.comps.args[0]] = t.comps.args[1]\n",
    "    return locs\n",
    "\n",
    "def detect_relations(T, classifiers):\n",
    "    locs = get_locs(T)\n",
    "    rels = []\n",
    "    for k, f in classifiers:\n",
    "        for x1, x2 in product(locs, locs):\n",
    "            if f(locs[x1], locs[x2]):\n",
    "                rels.append(create_fun(k, 'ab').app(x1).app(x2))\n",
    "    return rels\n",
    "    \n",
    "rels = detect_relations(sitmerge, location_relation_classifiers.items())\n",
    "sitmergerels = rectype_merges([sitmerge] + [RecType({gensym('rel'): rel}) for rel in rels])\n",
    "latex(sitmergerels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dog is to the left of a car\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{c}_\\text{dog} &:& \\text{dog}(x)\\\\\n",
       "\\text{c}_\\text{left} &:& \\text{left}(x, y)\\\\\n",
       "\\text{c}_\\text{car} &:& \\text{car}(y)\\\\\n",
       "\\text{y} &:& Ind\\\\\n",
       "\\text{x} &:& Ind\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_abc(prop_a, prop_b, rel):\n",
    "    '''Creates a record type describing two individuals and a relation between them.'''\n",
    "    return RecType({\n",
    "        'x': Ind,\n",
    "        'y': Ind,\n",
    "        'c_{' + prop_a + '}': create_fun(prop_a).app('x'),\n",
    "        'c_{' + prop_b + '}': create_fun(prop_b).app('y'),\n",
    "        'c_{' + rel + '}': create_fun(rel, 'ab').app('x').app('y'),\n",
    "    })\n",
    "\n",
    "print(\"A dog is to the left of a car\")\n",
    "question = create_abc('dog', 'car', 'left')\n",
    "latex(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{c_x : dog(x), c_rel : left(x, y), c_y : car(y), y : Ind, x : Ind}\n"
     ]
    }
   ],
   "source": [
    "from lark.lark import Lark\n",
    "ttr_parser = Lark(r'''\n",
    "?start: type\n",
    "?type: btype | rectype | ptype\n",
    "btype: name\n",
    "rectype: \"{\" tfield (\",\" tfield)* \"}\"\n",
    "tfield: sym \":\" type\n",
    "ptype: sym \"(\" args \")\"\n",
    "args: sym (\",\" sym)*\n",
    "?sym: name\n",
    "?name: /[a-zA-Z0-9{}_]+/\n",
    "%ignore \" \"\n",
    "''')\n",
    "\n",
    "def ttr_inflate(tree):\n",
    "    if tree.data == 'btype':\n",
    "        return BType(str(tree.children[0]))\n",
    "    elif tree.data == 'rectype':\n",
    "        return RecType(dict((str(f.children[0]), ttr_inflate(f.children[1])) for f in tree.children))\n",
    "    elif tree.data == 'ptype':\n",
    "        return mkptype(str(tree.children[0]), vars=tree.children[1].children)\n",
    "    \n",
    "def ttr_parse(s):\n",
    "    return ttr_inflate(ttr_parser.parse(s))\n",
    "\n",
    "s = '{c_rel : left(x, y), c_y : car(y), x : Ind, y : Ind, c_x : dog(x)}'\n",
    "T = ttr_parse(s)\n",
    "print(show(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dog is to the left of a car\n",
      "{c_3 : car(y), x : Ind, c_1 : dog(x), y : Ind, c_2 : left(x, y)}\n",
      "A car is to the left of a dog\n",
      "{c_3 : dog(y), x : Ind, c_1 : car(x), y : Ind, c_2 : left(x, y)}\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{c}_\\text{3} &:& \\text{dog}(y)\\\\\n",
       "\\text{x} &:& Ind\\\\\n",
       "\\text{c}_\\text{1} &:& \\text{car}(x)\\\\\n",
       "\\text{y} &:& Ind\\\\\n",
       "\\text{c}_\\text{2} &:& \\text{left}(x, y)\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(r'''\n",
    "%start S\n",
    "S[SEM=(\"x:Ind, y:Ind\", <?s(x) & ?vp(x, y)>)] -> NP[SEM=?s] VP[SEM=?vp]\n",
    "NP[SEM=<?det(?n)>] -> Det[SEM=?det] N[SEM=?n]\n",
    "Det[SEM=<\\P a.P(a)>] -> 'a' | 'an'\n",
    "N[SEM=<dog>] -> 'dog'\n",
    "N[SEM=<car>] -> 'car'\n",
    "N[SEM=<person>] -> 'person'\n",
    "N[SEM=<chair>] -> 'chair'\n",
    "VP[SEM=?pp] -> 'is' PP[SEM=?pp]\n",
    "PP[SEM=<\\a b.(?prep(a, b) & ?o(b))>] -> Prep[SEM=?prep] NP[SEM=?o]\n",
    "Prep[SEM=<left>] -> 'to' 'the' 'left' 'of'\n",
    "Prep[SEM=<right>] -> 'to' 'the' 'right' 'of'\n",
    "Prep[SEM=<above>] -> 'above'\n",
    "Prep[SEM=<under>] -> 'under'\n",
    "''')\n",
    "parser = nltk.FeatureChartParser(grammar)\n",
    "\n",
    "texts = [\n",
    "    'A dog is to the left of a car',\n",
    "    'A car is to the left of a dog',\n",
    "#     'There is a dog to the left of a car',\n",
    "#     'Is the dog to the left of the car',\n",
    "#     'Is there a dog to the left of the car',\n",
    "]\n",
    "\n",
    "def and_list(a):\n",
    "    \"\"\"Flatten a tree of And expressions.\"\"\"\n",
    "    from nltk.sem.logic import AndExpression\n",
    "    if isinstance(a, AndExpression):\n",
    "        return and_list(a.first) + and_list(a.second)\n",
    "    return [a]\n",
    "\n",
    "def parse_text(text):\n",
    "    trees = parser.parse(text.lower().split())\n",
    "    sem = nltk.sem.root_semrep(list(trees)[0])\n",
    "    fields = [sem[0]] + ['c_{}:{}'.format(i+1, str(x)) for i, x in enumerate(and_list(sem[1]))]\n",
    "    ttr_text = '{' + ', '.join(fields) + '}'\n",
    "    T = ttr_parse(ttr_text)\n",
    "    return T\n",
    "\n",
    "for text in texts:\n",
    "    print(text)\n",
    "    r = parse_text(text)\n",
    "    print(show(r))\n",
    "\n",
    "latex(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking text against image\n",
    "\n",
    "Essentially, we would like to check if the situation observed is a subtype of the situation described by the text/question, whether $Q \\sqsupseteq A$. A new problem here is that field labels do not match, even if the field values (the types) match. We thus need to consider all (?) relabelings of Q:\n",
    "\n",
    "A record type $T_1$ is a *relabel-subtype* of $T_2$ if there is a relabeling of $T_1$, $T_{1_{rlb}}$ where $T_{1_{rlb}} \\sqsubseteq T_2$.\n",
    "\n",
    "Could we forget field labels and just look at the two sets of field values? Not really, because we have dependent types, so $\\text{dog}(x_1) ≠ \\text{dog}(x_2)$. We need to carry out each candidate *relabeling* and check subtypeness. In practice, and in this case, relabeling the basic-type ($Ind$) fields is enough, because those are the only ones whose labels appear in dependent fields. For each basic-field relabeling, we can then kind of forget labels and just find subtypeness of field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_3': 'prop_{3}', 'x': 'x_{2}', 'c_1': 'prop_{2}', 'y': 'x_{3}', 'c_2': 'rel_{9}'}\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{equation}\\left[\\begin{array}{rcl}\n",
       "\\text{prop}_\\text{2} &:& \\text{car}(x_{2})\\\\\n",
       "\\text{x}_\\text{2} &:& Ind\\\\\n",
       "\\text{x}_\\text{3} &:& Ind\\\\\n",
       "\\text{prop}_\\text{3} &:& \\text{dog}(x_{3})\\\\\n",
       "\\text{rel}_\\text{9} &:& \\text{left}(x_{2}, x_{3})\n",
       "\\end{array}\\right]\\end{equation}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations, combinations\n",
    "\n",
    "def find_subtype_relabeling(T, U):\n",
    "    '''Could record type T be a sub type of record type U if relabeling in T is allowed?'''\n",
    "    # Find possible relabelings for basic-type fields\n",
    "    basic_label_permutations = set(ps[:len(basic_fields(U))] for ps in permutations(basic_fields(T)))\n",
    "    \n",
    "    for tks in basic_label_permutations:\n",
    "        # Copy U and try a basic-fields relabeling\n",
    "        U2 = copy_rectype(U)\n",
    "        rlb = list(zip(basic_fields(U), tks))\n",
    "        for uk, tk in rlb:\n",
    "            U2.Relabel(uk, tk)\n",
    "        \n",
    "        # For each U field, find a T field that is a subtype\n",
    "        match = dict()\n",
    "        for uk in nonbasic_fields(U2):\n",
    "            for tk in nonbasic_fields(T):\n",
    "                if T.comps.__dict__[tk].subtype_of(U2.comps.__dict__[uk]):\n",
    "                    match[uk] = tk\n",
    "                    break\n",
    "            if uk not in match:\n",
    "                break\n",
    "\n",
    "        # Successful if all non-basic fields match.\n",
    "        if len(match) == len(nonbasic_fields(U2)):\n",
    "            return dict(list(rlb) + list(match.items()))\n",
    "    return None\n",
    "\n",
    "obs = sitmergerels\n",
    "r = parse_text(texts[1])\n",
    "print(find_subtype_relabeling(obs, r))\n",
    "r2 = rectype_relabels(copy_rectype(r), find_subtype_relabeling(obs, r))\n",
    "print(obs.subtype_of(r2))\n",
    "latex(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

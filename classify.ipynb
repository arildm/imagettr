{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('pyttr')\n",
    "from pyttr import ttrtypes as ttr, utils as ttru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'palace'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify(path):\n",
    "    img = load_img(path, target_size=(224,224))\n",
    "    input = preprocess_input(np.array([img_to_array(img)]))\n",
    "    prediction = decode_predictions(model.predict(input))[0]\n",
    "    return prediction[0][1].replace('_', ' ')\n",
    "classify('res/canal.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = ttr.Possibility('M1')\n",
    "Ind = ttr.BType('Ind')\n",
    "Ind.in_poss(M)\n",
    "\n",
    "def see(path):\n",
    "    pred = ttr.Pred(classify(path), [Ind])\n",
    "    name = path.split('/')[-1].split('.')[0]\n",
    "    Ind.judge(name)\n",
    "    ttr.PType(pred, [name]).in_poss(M).judge(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M1:\n",
      "_____________________________________________\n",
      "Ind: [volcano, volcano2, canal, dogcar]\n",
      "palace(canal): [res/canal.jpg]\n",
      "volcano(volcano2): [res/volcano2.jpg]\n",
      "volcano(volcano): [res/volcano.jpg]\n",
      "Norfolk terrier(dogcar): [res/dogcar.jpg]\n",
      "_____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "see('res/volcano.jpg')\n",
    "see('res/volcano2.jpg')\n",
    "see('res/canal.jpg')\n",
    "see('res/dogcar.jpg')\n",
    "#see('/home/arildm/Pictures/star.png')\n",
    "#see('/home/arildm/Pictures/skocaj.png')\n",
    "print(ttru.show(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification as a witness condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res/volcano2.jpg is a volcano(x)\n",
      "res/canal.jpg is a palace(x)\n"
     ]
    }
   ],
   "source": [
    "words = ['volcano', 'palace', 'dog', 'canal']\n",
    "ptypes = []\n",
    "for word in words:\n",
    "    ptype = ttr.PType(ttr.Pred(word, [Ind]), ['x'])\n",
    "    ptype.learn_witness_condition(lambda path, word=word: classify(path) == word)\n",
    "    ptypes.append(ptype)\n",
    "for path in ['res/volcano2.jpg', 'res/canal.jpg', 'res/dogcar.jpg']:\n",
    "    for ptype in ptypes:\n",
    "        if ptype.query(path):\n",
    "            print(path + ' is a ' + ptype.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questionable \"object detector\" function\n",
    "\n",
    "Still with ResNet50, meaning only one class for the image, no object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{pfun : lambda x:Image . volcano(x), reg : <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x900 at 0x7FCB86B85080>}']\n"
     ]
    }
   ],
   "source": [
    "imageT = ttr.BType('Image')\n",
    "\n",
    "def odf(path):\n",
    "    det = set()\n",
    "    for ptype in ptypes:\n",
    "        if ptype.query(path):\n",
    "            det.add(ttr.RecType({\n",
    "                'reg': str(load_img(path)),\n",
    "                'pfun': ttr.Fun('x', imageT, ptype),\n",
    "            }))\n",
    "    return det\n",
    "            \n",
    "print([t.show() for t in odf('res/volcano2.jpg')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO\n",
    "\n",
    "Enter object detection.\n",
    "\n",
    "Requires OpenCV and [Darkflow](https://github.com/thtrieu/darkflow). yolo.weights is from [Yolo](https://pjreddie.com/darknet/yolo/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/darkflow/darkflow/dark/darknet.py:54: UserWarning: ./cfg/yolo.cfg not found, use yolo/yolo.cfg instead\n",
      "  cfg_path, FLAGS.model))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing yolo/yolo.cfg\n",
      "Loading yolo/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.014590978622436523s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "Finished in 7.629829406738281s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "\n",
    "options = {\"model\": \"yolo/yolo.cfg\", \"load\": \"yolo/yolo.weights\", \"threshold\": 0.1}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detector(cv_image):\n",
    "    s = set()\n",
    "    for o in tfnet.return_predict(imgcv):\n",
    "        if o['confidence'] > 0.1:\n",
    "            ptype = ttr.PType(ttr.Pred(o['label'], [Ind]), ['x'])\n",
    "            pfun = ttr.Fun('x', imageT, ptype)\n",
    "            s.add(ttr.RecType({'reg': (o['topleft'], o['bottomright']), 'pfun': pfun}))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{pfun : lambda x:Image . car(x), reg : ({x = 170, y = 89}, {x = 1019, y = 1006})}\n",
      "{pfun : lambda x:Image . chair(x), reg : ({x = 191, y = 308}, {x = 905, y = 1079})}\n",
      "{pfun : lambda x:Image . person(x), reg : ({x = 356, y = 236}, {x = 1065, y = 1072})}\n",
      "{pfun : lambda x:Image . dog(x), reg : ({x = 241, y = 320}, {x = 968, y = 1079})}\n",
      "{pfun : lambda x:Image . dog(x), reg : ({x = 706, y = 574}, {x = 1079, y = 1067})}\n",
      "{pfun : lambda x:Image . person(x), reg : ({x = 3, y = 697}, {x = 386, y = 1079})}\n"
     ]
    }
   ],
   "source": [
    "for t in object_detector(cv2.imread('res/dogcar.jpg')):\n",
    "    print(t.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what about the witness condition??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
